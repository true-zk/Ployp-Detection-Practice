{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Description: Use YOLO8 to Instance Segmentation\n",
    "@Author: Ken Zh0ng\n",
    "@date: 2024-06-04\n",
    "\"\"\"\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 32\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "model.info()\n",
    "results = model.train(data=\"dataset/yolo8_seg/data.yaml\", batch=32, epochs=100, imgsz=640, device=0, verbose=True, plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 12\n",
    "model = YOLO(\"yolov8x-seg.pt\")\n",
    "model.info()\n",
    "results = model.train(data=\"dataset/yolo8_seg/data.yaml\", batch=10, epochs=100, imgsz=640, device=0, verbose=True, plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 32\n",
    "model = YOLO(\"runs/segment/train/weights/best.pt\")\n",
    "metrics = model.val(conf=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 10\n",
    "model = YOLO(\"runs/segment/train2/weights/best.pt\")\n",
    "metrics = model.val(conf=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see one res\n",
    "import os\n",
    "testset_path = \"dataset/yolo8_seg/test/\"\n",
    "model = YOLO(\"runs/segment/train2/weights/best.pt\")\n",
    "res = model(os.path.join(testset_path, \"images\", \"800.jpg\"))\n",
    "# Process results list\n",
    "for result in res:\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    \n",
    "    print(\"xxxxx\")\n",
    "    print(type(masks))\n",
    "    print(masks.xyn)\n",
    "    print(type(masks.xyn))\n",
    "    print(len(masks.xyn))\n",
    "    print(type(masks.xyn[0]))\n",
    "    print(len(masks.xyn[0]))\n",
    "    print(\"yyyyyyyy\")\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAL IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongken/miniconda3/envs/yolo8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/800.jpg: 576x640 1 polyp, 7.5ms\n",
      "Speed: 5.9ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:03<10:04,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/801.jpg: 608x640 1 polyp, 7.6ms\n",
      "Speed: 3.2ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/802.jpg: 544x640 1 polyp, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/803.jpg: 544x640 1 polyp, 8.3ms\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/804.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/805.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:03<01:16,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/806.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.6ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/807.jpg: 544x640 2 polyps, 7.2ms\n",
      "Speed: 2.5ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/808.jpg: 576x640 1 polyp, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/809.jpg: 640x640 1 polyp, 7.1ms\n",
      "Speed: 2.7ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/810.jpg: 608x640 1 polyp, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:03<00:35,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/811.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/812.jpg: 544x640 1 polyp, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/813.jpg: 512x640 1 polyp, 8.1ms\n",
      "Speed: 2.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/814.jpg: 608x640 1 polyp, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/815.jpg: 544x640 1 polyp, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:03<00:20,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/816.jpg: 576x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/817.jpg: 544x640 1 polyp, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/818.jpg: 576x640 1 polyp, 7.2ms\n",
      "Speed: 2.5ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/819.jpg: 608x640 1 polyp, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/820.jpg: 416x640 1 polyp, 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:03<00:13, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/821.jpg: 640x640 1 polyp, 7.2ms\n",
      "Speed: 2.8ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/822.jpg: 608x640 2 polyps, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/823.jpg: 576x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/824.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 4.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/825.jpg: 512x640 1 polyp, 8.1ms\n",
      "Speed: 4.2ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:03<00:10, 17.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/826.jpg: 608x640 1 polyp, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/827.jpg: 608x640 1 polyp, 7.1ms\n",
      "Speed: 2.9ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/828.jpg: 640x608 1 polyp, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/829.jpg: 576x640 1 polyp, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/830.jpg: 576x640 1 polyp, 6.7ms\n",
      "Speed: 2.6ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [00:03<00:07, 22.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/831.jpg: 640x576 1 polyp, 7.9ms\n",
      "Speed: 2.3ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/832.jpg: 608x640 1 polyp, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/833.jpg: 640x640 1 polyp, 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/834.jpg: 608x640 1 polyp, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/835.jpg: 576x640 2 polyps, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [00:03<00:06, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/836.jpg: 608x640 (no detections), 8.2ms\n",
      "Speed: 2.7ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/837.jpg: 544x640 1 polyp, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/838.jpg: 576x640 1 polyp, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/839.jpg: 544x640 2 polyps, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/840.jpg: 576x640 1 polyp, 7.8ms\n",
      "Speed: 2.6ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:03<00:05, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/841.jpg: 576x640 1 polyp, 7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 5.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/842.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 3.8ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/843.jpg: 512x640 1 polyp, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/844.jpg: 576x640 2 polyps, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/845.jpg: 576x640 2 polyps, 6.8ms\n",
      "Speed: 2.6ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [00:04<00:04, 33.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/846.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/847.jpg: 544x640 1 polyp, 7.2ms\n",
      "Speed: 2.5ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/848.jpg: 576x640 1 polyp, 7.2ms\n",
      "Speed: 2.5ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/849.jpg: 640x448 1 polyp, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/850.jpg: 576x640 3 polyps, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/851.jpg: 608x640 1 polyp, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [00:04<00:03, 38.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/852.jpg: 608x640 1 polyp, 6.8ms\n",
      "Speed: 2.6ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/853.jpg: 576x640 1 polyp, 9.6ms\n",
      "Speed: 6.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/854.jpg: 544x640 1 polyp, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/855.jpg: 576x640 1 polyp, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/856.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [00:04<00:03, 39.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/857.jpg: 576x640 2 polyps, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/858.jpg: 544x640 2 polyps, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/859.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/860.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/861.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/862.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [00:04<00:03, 43.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/863.jpg: 544x640 3 polyps, 6.5ms\n",
      "Speed: 2.4ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/864.jpg: 576x640 1 polyp, 7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/865.jpg: 544x640 1 polyp, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/866.jpg: 608x640 1 polyp, 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/867.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/868.jpg: 544x640 2 polyps, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [00:04<00:02, 46.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/869.jpg: 576x640 1 polyp, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/870.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.6ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/871.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/872.jpg: 576x640 2 polyps, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/873.jpg: 480x640 1 polyp, 7.3ms\n",
      "Speed: 2.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/874.jpg: 640x576 1 polyp, 6.7ms\n",
      "Speed: 2.4ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [00:04<00:02, 49.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/875.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/876.jpg: 640x480 1 polyp, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/877.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/878.jpg: 608x640 1 polyp, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/879.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/880.jpg: 576x640 1 polyp, 6.2ms\n",
      "Speed: 2.4ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [00:04<00:02, 50.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/881.jpg: 608x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/882.jpg: 576x640 2 polyps, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/883.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/884.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.4ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/885.jpg: 576x640 1 polyp, 6.2ms\n",
      "Speed: 2.4ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/886.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.4ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [00:04<00:02, 52.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/887.jpg: 640x640 1 polyp, 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/888.jpg: 576x640 1 polyp, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/889.jpg: 608x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/890.jpg: 576x640 1 polyp, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/891.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.4ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/892.jpg: 640x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [00:04<00:02, 52.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/893.jpg: 576x640 (no detections), 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/894.jpg: 544x640 1 polyp, 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/895.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/896.jpg: 640x640 1 polyp, 6.8ms\n",
      "Speed: 2.4ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/897.jpg: 608x640 1 polyp, 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/898.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [00:05<00:01, 53.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/899.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/900.jpg: 544x640 1 polyp, 7.2ms\n",
      "Speed: 2.4ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/901.jpg: 576x640 2 polyps, 7.7ms\n",
      "Speed: 2.6ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/902.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.5ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/903.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.4ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/904.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:05<00:01, 53.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/905.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/906.jpg: 608x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/907.jpg: 544x640 1 polyp, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/908.jpg: 544x640 1 polyp, 6.6ms\n",
      "Speed: 2.4ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/909.jpg: 608x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/910.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [00:05<00:01, 53.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/911.jpg: 640x640 1 polyp, 7.1ms\n",
      "Speed: 2.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/912.jpg: 544x640 1 polyp, 7.2ms\n",
      "Speed: 2.4ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/913.jpg: 576x640 2 polyps, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/914.jpg: 576x640 1 polyp, 6.8ms\n",
      "Speed: 2.5ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/915.jpg: 640x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/916.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 117/200 [00:05<00:01, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/917.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.4ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/918.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/919.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.4ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/920.jpg: 576x640 1 polyp, 5.9ms\n",
      "Speed: 2.4ms preprocess, 5.9ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/921.jpg: 576x640 1 polyp, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/922.jpg: 576x640 1 polyp, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 123/200 [00:05<00:01, 53.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/923.jpg: 512x640 1 polyp, 6.9ms\n",
      "Speed: 2.9ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/924.jpg: 544x640 3 polyps, 6.8ms\n",
      "Speed: 2.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/925.jpg: 576x640 1 polyp, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/926.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.4ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/927.jpg: 576x640 1 polyp, 6.2ms\n",
      "Speed: 2.4ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/928.jpg: 608x640 1 polyp, 6.8ms\n",
      "Speed: 2.6ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 129/200 [00:05<00:01, 51.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/929.jpg: 640x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/930.jpg: 640x640 1 polyp, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/931.jpg: 608x640 1 polyp, 7.6ms\n",
      "Speed: 2.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/932.jpg: 576x640 1 polyp, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/933.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/934.jpg: 640x576 2 polyps, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 135/200 [00:05<00:01, 51.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/935.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/936.jpg: 544x640 1 polyp, 7.4ms\n",
      "Speed: 2.4ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/937.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/938.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.6ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/939.jpg: 448x640 1 polyp, 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/940.jpg: 576x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [00:05<00:01, 50.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/941.jpg: 576x640 (no detections), 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/942.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.7ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/943.jpg: 576x640 2 polyps, 6.4ms\n",
      "Speed: 2.6ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/944.jpg: 576x640 (no detections), 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/945.jpg: 608x640 2 polyps, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/946.jpg: 544x640 1 polyp, 7.0ms\n",
      "Speed: 2.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 147/200 [00:05<00:01, 50.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/947.jpg: 640x512 (no detections), 7.5ms\n",
      "Speed: 2.2ms preprocess, 7.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/948.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/949.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/950.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.3ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/951.jpg: 576x640 1 polyp, 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/952.jpg: 576x640 (no detections), 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 153/200 [00:06<00:00, 51.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/953.jpg: 512x640 1 polyp, 6.8ms\n",
      "Speed: 2.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/954.jpg: 576x640 1 polyp, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/955.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/956.jpg: 608x640 (no detections), 7.0ms\n",
      "Speed: 2.7ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/957.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/958.jpg: 608x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159/200 [00:06<00:00, 51.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/959.jpg: 576x640 2 polyps, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/960.jpg: 448x640 1 polyp, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/961.jpg: 576x640 2 polyps, 7.1ms\n",
      "Speed: 2.5ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/962.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/963.jpg: 576x640 2 polyps, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/964.jpg: 544x640 2 polyps, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 165/200 [00:06<00:00, 51.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/965.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/966.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/967.jpg: 576x640 1 polyp, 6.3ms\n",
      "Speed: 2.5ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/968.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/969.jpg: 576x640 1 polyp, 6.5ms\n",
      "Speed: 2.7ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/970.jpg: 576x640 2 polyps, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [00:06<00:00, 50.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/971.jpg: 608x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/972.jpg: 544x640 2 polyps, 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/973.jpg: 576x640 2 polyps, 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/974.jpg: 576x640 1 polyp, 6.4ms\n",
      "Speed: 2.6ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/975.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.6ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/976.jpg: 608x640 1 polyp, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/200 [00:06<00:00, 50.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/977.jpg: 576x640 1 polyp, 6.8ms\n",
      "Speed: 2.5ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/978.jpg: 512x640 1 polyp, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/979.jpg: 544x640 1 polyp, 7.2ms\n",
      "Speed: 2.9ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/980.jpg: 608x640 1 polyp, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/981.jpg: 544x640 2 polyps, 7.4ms\n",
      "Speed: 2.4ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/982.jpg: 608x640 1 polyp, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183/200 [00:06<00:00, 49.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/983.jpg: 576x640 1 polyp, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/984.jpg: 608x640 1 polyp, 7.4ms\n",
      "Speed: 2.7ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/985.jpg: 544x640 1 polyp, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/986.jpg: 544x640 1 polyp, 6.5ms\n",
      "Speed: 2.4ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/987.jpg: 608x640 1 polyp, 6.8ms\n",
      "Speed: 2.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 188/200 [00:06<00:00, 48.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/988.jpg: 576x640 1 polyp, 6.8ms\n",
      "Speed: 2.6ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/989.jpg: 576x640 1 polyp, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/991.jpg: 512x640 1 polyp, 7.0ms\n",
      "Speed: 2.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/992.jpg: 544x640 1 polyp, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/993.jpg: 512x640 1 polyp, 7.0ms\n",
      "Speed: 2.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194/200 [00:06<00:00, 50.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/994.jpg: 512x640 1 polyp, 6.3ms\n",
      "Speed: 2.2ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/995.jpg: 576x640 1 polyp, 7.2ms\n",
      "Speed: 2.7ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/996.jpg: 544x640 1 polyp, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/997.jpg: 576x640 1 polyp, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/998.jpg: 576x640 1 polyp, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/999.jpg: 576x640 1 polyp, 6.6ms\n",
      "Speed: 2.6ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.6939754100758398, for model: runs/segment/train/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# IOU test\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "testimgs_path = \"dataset/yolo8_seg/test/images\"\n",
    "testlabels_path = \"dataset/yolo8_seg/test/raw_labels\"\n",
    "\n",
    "model = YOLO(\"runs/segment/train/weights/best.pt\")\n",
    "\n",
    "avg_IOU = 0\n",
    "testset_size = len(os.listdir(testimgs_path))\n",
    "print(testset_size)\n",
    "\n",
    "total_tests = os.listdir(testimgs_path)\n",
    "bar = tqdm(total_tests)\n",
    "for file_n in bar:\n",
    "    if file_n in (\"990.jpg\") :\n",
    "        continue\n",
    "    # if file_n in (\"869.jpg\", \"907.jpg\", \"991.jpg\", \"990.jpg\") :\n",
    "    #     continue\n",
    "    reses = model.predict(os.path.join(testimgs_path, file_n))\n",
    "    \n",
    "    assert len(reses) == 1\n",
    "    res = reses[0]\n",
    "    if res:\n",
    "        pred_masks = res.masks.xy\n",
    "    else:\n",
    "        continue # no res\n",
    "    \n",
    "    if pred_masks is None:\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(testlabels_path, file_n.replace(\".jpg\", \".txt\")), \"r\") as f:\n",
    "        gt_masks = []\n",
    "        for line in f.readlines():\n",
    "            line = line.split(\" \")\n",
    "            assert len(line) % 2 == 0\n",
    "            xl = [float(x) for x in line[::2]]\n",
    "            yl = [float(y) for y in line[1::2]]\n",
    "            gt_masks.append(np.array([xl, yl], dtype=np.float32).T)\n",
    "    \n",
    "    # assert len(pred_masks) == len(gt_masks)\n",
    "    \n",
    "    # cal ious MAT\n",
    "    ious = np.zeros((len(pred_masks), len(gt_masks)))\n",
    "    for i, pred_mask in enumerate(pred_masks):\n",
    "        for j, gt_mask in enumerate(gt_masks):\n",
    "            intersection_area = cv2.intersectConvexConvex(pred_mask, gt_mask)[0]\n",
    "            union_area = cv2.contourArea(pred_mask) + cv2.contourArea(gt_mask) - intersection_area\n",
    "            if union_area<=0:\n",
    "                ious[i, j] = 0\n",
    "                continue\n",
    "            ious[i, j] = intersection_area / union_area\n",
    "    \n",
    "    cur_avg_iou = 0\n",
    "    for i in range(len(pred_masks)):\n",
    "        cur_avg_iou += ious[i, np.argmax(ious[i])]\n",
    "    cur_avg_iou /= len(pred_masks)\n",
    "    \n",
    "    avg_IOU += cur_avg_iou\n",
    "IOU = avg_IOU / (testset_size - 3)\n",
    "print(f\"IOU: {IOU}, for model: {model.model_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-50: 0.7349831990629428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/zhongken/ai_cross_application/fn/dataset/yolo8_seg/test/images/869.jpg: 576x640 2 polyps, 36.5ms\n",
      "Speed: 3.1ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "2\n",
      "1\n",
      "95378.65625\n",
      "[[     215.76      66.737]\n",
      " [     214.78      67.709]\n",
      " [     191.46      67.709]\n",
      " [     191.46      86.175]\n",
      " [     190.49      87.147]\n",
      " [     190.49      213.49]\n",
      " [     191.46      214.46]\n",
      " [     191.46      225.15]\n",
      " [     192.43      226.12]\n",
      " [     192.43      228.07]\n",
      " [     195.35      228.07]\n",
      " [     196.32      229.04]\n",
      " [     197.29      229.04]\n",
      " [     202.15       233.9]\n",
      " [     202.15      234.87]\n",
      " [     205.07      237.79]\n",
      " [     205.07      238.76]\n",
      " [     206.04      239.73]\n",
      " [     206.04       240.7]\n",
      " [     207.98      242.65]\n",
      " [     207.98      245.56]\n",
      " [     207.01      246.53]\n",
      " [     207.01      247.51]\n",
      " [     206.04      248.48]\n",
      " [     206.04      250.42]\n",
      " [     204.09      252.37]\n",
      " [     204.09      253.34]\n",
      " [     203.12      254.31]\n",
      " [     202.15      254.31]\n",
      " [     203.12      255.28]\n",
      " [     204.09      255.28]\n",
      " [     206.04      257.23]\n",
      " [     206.04       258.2]\n",
      " [     207.01      259.17]\n",
      " [     207.01      264.03]\n",
      " [     206.04         265]\n",
      " [     206.04      267.92]\n",
      " [     205.07      268.89]\n",
      " [     205.07      269.86]\n",
      " [     202.15      272.78]\n",
      " [     201.18      272.78]\n",
      " [     200.21      273.75]\n",
      " [     199.23      273.75]\n",
      " [     198.26      274.72]\n",
      " [     197.29      274.72]\n",
      " [     196.32      275.69]\n",
      " [     192.43      275.69]\n",
      " [     192.43      278.61]\n",
      " [     191.46      279.58]\n",
      " [     191.46      299.99]\n",
      " [     192.43      300.96]\n",
      " [     192.43      301.93]\n",
      " [     194.38      301.93]\n",
      " [     195.35       302.9]\n",
      " [     198.26       302.9]\n",
      " [     199.23      303.88]\n",
      " [     200.21      303.88]\n",
      " [     201.18      304.85]\n",
      " [     202.15      304.85]\n",
      " [     203.12      305.82]\n",
      " [     204.09      305.82]\n",
      " [     205.07      306.79]\n",
      " [     206.04      306.79]\n",
      " [     207.98      308.73]\n",
      " [     208.95      308.73]\n",
      " [      210.9      310.68]\n",
      " [     215.76      310.68]\n",
      " [     218.67      307.76]\n",
      " [     219.64      307.76]\n",
      " [     221.59      305.82]\n",
      " [     222.56      305.82]\n",
      " [     223.53      304.85]\n",
      " [      224.5      304.85]\n",
      " [     225.48      303.88]\n",
      " [     227.42      303.88]\n",
      " [     228.39       302.9]\n",
      " [     235.19       302.9]\n",
      " [     236.17      301.93]\n",
      " [     243.94      301.93]\n",
      " [     244.91      300.96]\n",
      " [     249.77      300.96]\n",
      " [     251.72       302.9]\n",
      " [     252.69       302.9]\n",
      " [     257.55      307.76]\n",
      " [     257.55      308.73]\n",
      " [     261.43      312.62]\n",
      " [     261.43      313.59]\n",
      " [     262.41      314.57]\n",
      " [     263.38      314.57]\n",
      " [     264.35      315.54]\n",
      " [     265.32      315.54]\n",
      " [     267.27      317.48]\n",
      " [     268.24      317.48]\n",
      " [     270.18      319.43]\n",
      " [     271.15      319.43]\n",
      " [     272.12       320.4]\n",
      " [      273.1       320.4]\n",
      " [     274.07      321.37]\n",
      " [     276.01      321.37]\n",
      " [     276.98      322.34]\n",
      " [     278.93      322.34]\n",
      " [      279.9      321.37]\n",
      " [     298.37      321.37]\n",
      " [     299.34       320.4]\n",
      " [     309.06       320.4]\n",
      " [     310.03      319.43]\n",
      " [     315.86      319.43]\n",
      " [     316.83      318.45]\n",
      " [     319.75      318.45]\n",
      " [     320.72      317.48]\n",
      " [     322.66      317.48]\n",
      " [     323.63      316.51]\n",
      " [     325.58      316.51]\n",
      " [     326.55      315.54]\n",
      " [     328.49      315.54]\n",
      " [     329.47      314.57]\n",
      " [     331.41      314.57]\n",
      " [     332.38      313.59]\n",
      " [     333.35      313.59]\n",
      " [     334.33      312.62]\n",
      " [      335.3      312.62]\n",
      " [     336.27      311.65]\n",
      " [     337.24      311.65]\n",
      " [     339.18      309.71]\n",
      " [     340.16      309.71]\n",
      " [     341.13      308.73]\n",
      " [      342.1      308.73]\n",
      " [     345.02      305.82]\n",
      " [     345.99      305.82]\n",
      " [     351.82      299.99]\n",
      " [     352.79      299.99]\n",
      " [     357.65      295.13]\n",
      " [     358.62      295.13]\n",
      " [     362.51      291.24]\n",
      " [     363.48      291.24]\n",
      " [     367.37      287.35]\n",
      " [     368.34      287.35]\n",
      " [     371.26      284.44]\n",
      " [     372.23      284.44]\n",
      " [     374.17      282.49]\n",
      " [     375.14      282.49]\n",
      " [     381.95      275.69]\n",
      " [     382.92      275.69]\n",
      " [     383.89      274.72]\n",
      " [     383.89      273.75]\n",
      " [     387.78      269.86]\n",
      " [     387.78      268.89]\n",
      " [     389.72      266.94]\n",
      " [     389.72      265.97]\n",
      " [     392.64      263.06]\n",
      " [     392.64      262.08]\n",
      " [     395.55      259.17]\n",
      " [     395.55       258.2]\n",
      " [     396.52      257.23]\n",
      " [     396.52      256.25]\n",
      " [     399.44      253.34]\n",
      " [     399.44      252.37]\n",
      " [     401.38      250.42]\n",
      " [     401.38      249.45]\n",
      " [     403.33      247.51]\n",
      " [     403.33      246.53]\n",
      " [      404.3      245.56]\n",
      " [      404.3      244.59]\n",
      " [     406.24      242.65]\n",
      " [     406.24      241.68]\n",
      " [     408.19      239.73]\n",
      " [     408.19      238.76]\n",
      " [     410.13      236.82]\n",
      " [     410.13      235.84]\n",
      " [      411.1      234.87]\n",
      " [      411.1       233.9]\n",
      " [     412.08      232.93]\n",
      " [     412.08      230.98]\n",
      " [     413.05      230.01]\n",
      " [     413.05      229.04]\n",
      " [     414.02      228.07]\n",
      " [     414.02      226.12]\n",
      " [     414.99      225.15]\n",
      " [     414.99      222.24]\n",
      " [     415.96      221.27]\n",
      " [     415.96      218.35]\n",
      " [     416.93      217.38]\n",
      " [     416.93       202.8]\n",
      " [     415.96      201.83]\n",
      " [     415.96      199.88]\n",
      " [     414.99      198.91]\n",
      " [     414.99      197.94]\n",
      " [     414.02      196.97]\n",
      " [     414.02         196]\n",
      " [     413.05      195.02]\n",
      " [     413.05      194.05]\n",
      " [     412.08      193.08]\n",
      " [     412.08      190.17]\n",
      " [      411.1      189.19]\n",
      " [      411.1      172.67]\n",
      " [     410.13       171.7]\n",
      " [     410.13      167.81]\n",
      " [     409.16      166.84]\n",
      " [     409.16       164.9]\n",
      " [     408.19      163.93]\n",
      " [     408.19      161.01]\n",
      " [     407.22      160.04]\n",
      " [     407.22      157.12]\n",
      " [     406.24      156.15]\n",
      " [     406.24      155.18]\n",
      " [      404.3      153.23]\n",
      " [      404.3      152.26]\n",
      " [     403.33      151.29]\n",
      " [     403.33      149.35]\n",
      " [     402.36      148.38]\n",
      " [     402.36       147.4]\n",
      " [     400.41      145.46]\n",
      " [     400.41      144.49]\n",
      " [     399.44      143.52]\n",
      " [     399.44      142.54]\n",
      " [     396.52      139.63]\n",
      " [     396.52      138.66]\n",
      " [     395.55      137.68]\n",
      " [     395.55      136.71]\n",
      " [     392.64       133.8]\n",
      " [     392.64      132.82]\n",
      " [     390.69      130.88]\n",
      " [     390.69      129.91]\n",
      " [     387.78      126.99]\n",
      " [     387.78      126.02]\n",
      " [     383.89      122.13]\n",
      " [     383.89      121.16]\n",
      " [     380.98      118.25]\n",
      " [     380.98      117.28]\n",
      " [     376.12      112.42]\n",
      " [     376.12      111.44]\n",
      " [     375.14      110.47]\n",
      " [     374.17      110.47]\n",
      " [     372.23      108.53]\n",
      " [     371.26      108.53]\n",
      " [     369.31      106.58]\n",
      " [     368.34      106.58]\n",
      " [      366.4      104.64]\n",
      " [     365.43      104.64]\n",
      " [     363.48       102.7]\n",
      " [     362.51       102.7]\n",
      " [     361.54      101.72]\n",
      " [     360.57      101.72]\n",
      " [     359.59      100.75]\n",
      " [     358.62      100.75]\n",
      " [     356.68      98.809]\n",
      " [     355.71      98.809]\n",
      " [     354.73      97.838]\n",
      " [     352.79      97.838]\n",
      " [     350.85      95.894]\n",
      " [     349.88      95.894]\n",
      " [      348.9      94.922]\n",
      " [     347.93      94.922]\n",
      " [     346.96       93.95]\n",
      " [     345.02       93.95]\n",
      " [     344.04      92.978]\n",
      " [      342.1      92.978]\n",
      " [     341.13      92.006]\n",
      " [     340.16      92.006]\n",
      " [     339.18      91.034]\n",
      " [      335.3      91.034]\n",
      " [     334.33      90.062]\n",
      " [     325.58      90.062]\n",
      " [     324.61      89.091]\n",
      " [     321.69      89.091]\n",
      " [     320.72      88.119]\n",
      " [     318.77      88.119]\n",
      " [      317.8      87.147]\n",
      " [     315.86      87.147]\n",
      " [     314.89      86.175]\n",
      " [     312.94      86.175]\n",
      " [     311.97      85.203]\n",
      " [     310.03      85.203]\n",
      " [     309.06      84.231]\n",
      " [     308.08      84.231]\n",
      " [     307.11      83.259]\n",
      " [     305.17      83.259]\n",
      " [      304.2      82.287]\n",
      " [     302.25      82.287]\n",
      " [     301.28      81.316]\n",
      " [     299.34      81.316]\n",
      " [     298.37      80.344]\n",
      " [     297.39      80.344]\n",
      " [     296.42      79.372]\n",
      " [     294.48      79.372]\n",
      " [     293.51        78.4]\n",
      " [     291.56        78.4]\n",
      " [     290.59      77.428]\n",
      " [     288.65      77.428]\n",
      " [     287.68      76.456]\n",
      " [      286.7      76.456]\n",
      " [     285.73      75.484]\n",
      " [     284.76      75.484]\n",
      " [     283.79      74.512]\n",
      " [     281.84      74.512]\n",
      " [     280.87      73.541]\n",
      " [     278.93      73.541]\n",
      " [     277.96      72.569]\n",
      " [     276.98      72.569]\n",
      " [     276.01      71.597]\n",
      " [     274.07      71.597]\n",
      " [      273.1      70.625]\n",
      " [     271.15      70.625]\n",
      " [     270.18      69.653]\n",
      " [     267.27      69.653]\n",
      " [     266.29      68.681]\n",
      " [     264.35      68.681]\n",
      " [     263.38      67.709]\n",
      " [     234.22      67.709]\n",
      " [     233.25      66.737]]\n",
      "[[        173           7]\n",
      " [        171           9]\n",
      " [        170           9]\n",
      " ...\n",
      " [        175          14]\n",
      " [        174          13]\n",
      " [        174           8]]\n"
     ]
    }
   ],
   "source": [
    "# IOU test\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "testimgs_path = \"dataset/yolo8_seg/test/images\"\n",
    "testlabels_path = \"dataset/yolo8_seg/test/raw_labels\"\n",
    "\n",
    "model = YOLO(\"runs/segment/train2/weights/best.pt\")\n",
    "\n",
    "file_n = \"869.jpg\"\n",
    "\n",
    "reses = model.predict(os.path.join(testimgs_path, file_n))\n",
    "\n",
    "assert len(reses) == 1\n",
    "res = reses[0]\n",
    "if res:\n",
    "    pred_masks = res.masks.xy\n",
    "else:\n",
    "    print(\"no res\")\n",
    "\n",
    "with open(os.path.join(testlabels_path, file_n.replace(\".jpg\", \".txt\")), \"r\") as f:\n",
    "    gt_masks = []\n",
    "    for line in f.readlines():\n",
    "        line = line.split(\" \")\n",
    "        assert len(line) % 2 == 0\n",
    "        xl = [float(x) for x in line[::2]]\n",
    "        yl = [float(y) for y in line[1::2]]\n",
    "        gt_masks.append(np.array([xl, yl], dtype=np.float32).T)\n",
    "        \n",
    "print(len(pred_masks))\n",
    "print(len(gt_masks))\n",
    "intersection_area, _ = cv2.intersectConvexConvex(pred_masks[0], gt_masks[0])\n",
    "print(intersection_area)\n",
    "print(pred_masks[1])\n",
    "print(gt_masks[0])\n",
    "# intersection_area = cv2.intersectConvexConvex(pred_masks[1], gt_masks[0])[0]\n",
    "# print(intersection_area)\n",
    "# cal ious MAT\n",
    "# ious = np.zeros((len(pred_masks), len(gt_masks)))\n",
    "# for i, pred_mask in enumerate(pred_masks):\n",
    "#     for j, gt_mask in enumerate(gt_masks):\n",
    "#         intersection_area = cv2.intersectConvexConvex(pred_mask, gt_mask)[0]\n",
    "        # union_area = cv2.contourArea(pred_mask) + cv2.contourArea(gt_mask) - intersection_area\n",
    "        # assert union_area > 0\n",
    "        # ious[i, j] = intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
